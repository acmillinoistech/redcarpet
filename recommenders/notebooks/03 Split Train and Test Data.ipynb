{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Train and Test Data\n",
    "\n",
    "## Recommended Reading\n",
    "\n",
    "- **Surprise!** A Python scikit for recommender systems. [Module Page](http://surpriselib.com/)\n",
    "- **Kaggle:** [Recommender Systems in Python 101](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101)\n",
    "- **Towards Data Science:** [Evaluation Metrics for Recommender Systems](https://towardsdatascience.com/evaluation-metrics-for-recommender-systems-df56c6611093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load module from another directory\n",
    "import shutil\n",
    "shutil.copyfile(src=\"../scripts/redcarpet.py\", dst=\"../notebooks/redcarpet.py\")\n",
    "from redcarpet import nonzero_index_set, mat_to_sets, write_kaggle_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>reactions</th>\n",
       "      <th>stars</th>\n",
       "      <th>joined</th>\n",
       "      <th>categories</th>\n",
       "      <th>in_13_reasons_why</th>\n",
       "      <th>in_90_day_fiance</th>\n",
       "      <th>in_actors</th>\n",
       "      <th>...</th>\n",
       "      <th>in_ufc</th>\n",
       "      <th>in_vanderpump_rules</th>\n",
       "      <th>in_venture_capitalists</th>\n",
       "      <th>in_viners</th>\n",
       "      <th>in_vlog_squad</th>\n",
       "      <th>in_voice_actors</th>\n",
       "      <th>in_winter_sports</th>\n",
       "      <th>in_writers</th>\n",
       "      <th>in_younow</th>\n",
       "      <th>in_youtubers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perezhilton</td>\n",
       "      <td>Perez Hilton</td>\n",
       "      <td>27.0</td>\n",
       "      <td>924</td>\n",
       "      <td>5.0</td>\n",
       "      <td>April 2018</td>\n",
       "      <td>[Reality TV, Commentators, Featured]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>andydick</td>\n",
       "      <td>Andy Dick</td>\n",
       "      <td>99.0</td>\n",
       "      <td>340</td>\n",
       "      <td>4.9</td>\n",
       "      <td>October 2018</td>\n",
       "      <td>[Reality TV, Comedians, Featured, Actors]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tjlavin</td>\n",
       "      <td>TJ Lavin</td>\n",
       "      <td>80.0</td>\n",
       "      <td>291</td>\n",
       "      <td>5.0</td>\n",
       "      <td>February 2018</td>\n",
       "      <td>[Reality TV, Riders, Featured, Extreme Sports,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>carsonkressley</td>\n",
       "      <td>Carson Kressley</td>\n",
       "      <td>59.0</td>\n",
       "      <td>290</td>\n",
       "      <td>5.0</td>\n",
       "      <td>October 2018</td>\n",
       "      <td>[Reality TV, Bravo, Stylists, Featured, Actors...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>riffraff</td>\n",
       "      <td>RiFF RAFF</td>\n",
       "      <td>75.0</td>\n",
       "      <td>402</td>\n",
       "      <td>4.7</td>\n",
       "      <td>December 2017</td>\n",
       "      <td>[Rappers, Featured, Musicians]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id             name  price  reactions  stars         joined  \\\n",
       "0     perezhilton     Perez Hilton   27.0        924    5.0     April 2018   \n",
       "1        andydick        Andy Dick   99.0        340    4.9   October 2018   \n",
       "2         tjlavin         TJ Lavin   80.0        291    5.0  February 2018   \n",
       "3  carsonkressley  Carson Kressley   59.0        290    5.0   October 2018   \n",
       "4        riffraff        RiFF RAFF   75.0        402    4.7  December 2017   \n",
       "\n",
       "                                          categories  in_13_reasons_why  \\\n",
       "0               [Reality TV, Commentators, Featured]                0.0   \n",
       "1          [Reality TV, Comedians, Featured, Actors]                0.0   \n",
       "2  [Reality TV, Riders, Featured, Extreme Sports,...                0.0   \n",
       "3  [Reality TV, Bravo, Stylists, Featured, Actors...                0.0   \n",
       "4                     [Rappers, Featured, Musicians]                0.0   \n",
       "\n",
       "   in_90_day_fiance  in_actors  ...  in_ufc  in_vanderpump_rules  \\\n",
       "0               0.0        0.0  ...     0.0                  0.0   \n",
       "1               0.0        1.0  ...     0.0                  0.0   \n",
       "2               0.0        0.0  ...     0.0                  0.0   \n",
       "3               0.0        1.0  ...     0.0                  0.0   \n",
       "4               0.0        0.0  ...     0.0                  0.0   \n",
       "\n",
       "   in_venture_capitalists  in_viners  in_vlog_squad  in_voice_actors  \\\n",
       "0                     0.0        0.0            0.0              0.0   \n",
       "1                     0.0        0.0            0.0              0.0   \n",
       "2                     0.0        0.0            0.0              0.0   \n",
       "3                     0.0        0.0            0.0              0.0   \n",
       "4                     0.0        0.0            0.0              0.0   \n",
       "\n",
       "   in_winter_sports  in_writers  in_younow  in_youtubers  \n",
       "0               0.0         0.0        0.0           0.0  \n",
       "1               0.0         0.0        0.0           0.0  \n",
       "2               0.0         0.0        0.0           0.0  \n",
       "3               0.0         0.0        0.0           0.0  \n",
       "4               0.0         0.0        0.0           0.0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_file = \"../input/talent.pkl\"\n",
    "item_records, COLUMN_LABELS, READABLE_LABELS, ATTRIBUTES = pickle.load(open(item_file, \"rb\"))\n",
    "item_df = pd.DataFrame(item_records)[ATTRIBUTES + COLUMN_LABELS].fillna(value=0)\n",
    "ITEM_NAMES = item_df[\"name\"].values\n",
    "ITEM_IDS = item_df[\"id\"].values\n",
    "item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Perez Hilton</th>\n",
       "      <th>Andy Dick</th>\n",
       "      <th>TJ Lavin</th>\n",
       "      <th>Carson Kressley</th>\n",
       "      <th>RiFF RAFF</th>\n",
       "      <th>Chumlee</th>\n",
       "      <th>Gilbert Gottfried</th>\n",
       "      <th>Ice T</th>\n",
       "      <th>Ben Higgins</th>\n",
       "      <th>Evan Breen</th>\n",
       "      <th>...</th>\n",
       "      <th>Chris Jai Alex</th>\n",
       "      <th>Peter Dickson</th>\n",
       "      <th>Laura Perlongo</th>\n",
       "      <th>Anna del Gaizo</th>\n",
       "      <th>Zach Harper</th>\n",
       "      <th>John Oberg</th>\n",
       "      <th>Zac Pullam</th>\n",
       "      <th>Kansas Bowling</th>\n",
       "      <th>Matt Cirulnick</th>\n",
       "      <th>Caleb Senzel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Perez Hilton  Andy Dick  TJ Lavin  Carson Kressley  RiFF RAFF  Chumlee  \\\n",
       "0             1          0         0                0          1        0   \n",
       "1             1          0         0                0          0        0   \n",
       "2             0          0         0                0          0        0   \n",
       "3             1          0         0                1          0        0   \n",
       "4             1          0         0                0          0        0   \n",
       "\n",
       "   Gilbert Gottfried  Ice T  Ben Higgins  Evan Breen  ...  Chris Jai Alex  \\\n",
       "0                  1      0            0           0  ...               0   \n",
       "1                  0      0            0           0  ...               0   \n",
       "2                  0      0            0           0  ...               0   \n",
       "3                  0      0            0           0  ...               0   \n",
       "4                  0      0            0           0  ...               0   \n",
       "\n",
       "   Peter Dickson  Laura Perlongo  Anna del Gaizo  Zach Harper  John Oberg  \\\n",
       "0              0               0               0            0           0   \n",
       "1              0               0               0            0           0   \n",
       "2              0               0               0            0           0   \n",
       "3              0               0               0            0           0   \n",
       "4              0               0               0            0           0   \n",
       "\n",
       "   Zac Pullam  Kansas Bowling  Matt Cirulnick  Caleb Senzel  \n",
       "0           0               0               0             0  \n",
       "1           0               0               0             0  \n",
       "2           0               0               0             0  \n",
       "3           0               0               0             0  \n",
       "4           0               0               0             0  \n",
       "\n",
       "[5 rows x 5392 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like_file = \"../input/likes.pkl\"\n",
    "like_csr = pickle.load(open(like_file, \"rb\"))\n",
    "like_mat = np.array(like_csr.todense())\n",
    "like_df = pd.DataFrame(like_mat, columns=ITEM_NAMES)\n",
    "like_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Train/Test/Input/Hidden Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def make_test_input(m_test, min_entries=3, seed=0):\n",
    "    \"\"\"\n",
    "    Randomly removes non-zero entries from rows in a numpy matrix\n",
    "    leaving exactly {min_entries} non-zero entries per row.\n",
    "    params:\n",
    "        m_test: numpy matrix of test data\n",
    "        min_entries: number of entries to leave in each row\n",
    "        seed: seed for pseudorandomness\n",
    "    returns:\n",
    "        m_input: new numpy matrix with some entries removed\n",
    "        m_hidden: new numpy matrix of the removed entries\n",
    "        s_input: list of sets with some entries removed\n",
    "        s_hidden: list of sets of the removed entries\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    m_input = m_test.copy()\n",
    "    m_hidden = np.zeros(m_input.shape)\n",
    "    s_hidden = []\n",
    "    for ridx, row in enumerate(m_input):\n",
    "        idxs = nonzero_index_set(row)\n",
    "        to_remove = len(idxs) - min_entries\n",
    "        rems = np.random.choice(list(idxs), size=to_remove)\n",
    "        for cidx in rems:\n",
    "            m_input[ridx][cidx] = 0\n",
    "            m_hidden[ridx][cidx] = 1\n",
    "        s_hidden.append(set(rems))\n",
    "    s_input = mat_to_sets(m_input)\n",
    "    return m_input, m_hidden, s_input, s_hidden\n",
    "\n",
    "\n",
    "def recs_train_test_split(mat, test_size=0.2, min_entries=3, seed=0):\n",
    "    \"\"\"\n",
    "    Splits a transaction matrix into train and test data.\n",
    "    params:\n",
    "        mat: numpy matrix of all data\n",
    "        test_size: proportion of dataset to hold for testing\n",
    "        min_entries: number of entries to leave in each test row\n",
    "        seed: seed for pseudorandomness\n",
    "    returns:\n",
    "        m_train: numpy matrix of train data\n",
    "        m_test: numpy matrix of test data\n",
    "        m_input: numpy matrix of test data, with some entries removed\n",
    "        m_hidden: numpy matrix of entries removed from test data\n",
    "        s_train: list of sets of train data\n",
    "        s_test: list of sets of test data\n",
    "        s_input: list of sets of test data, with some entries removed\n",
    "        s_hidden: list of sets of entries removed from test data\n",
    "    \"\"\"\n",
    "    m_train, m_test = train_test_split(mat, test_size=test_size, shuffle=True, random_state=seed)\n",
    "    m_input, m_hidden, s_input, s_hidden = make_test_input(m_test, min_entries=min_entries, seed=seed)\n",
    "    s_train = mat_to_sets(m_train)\n",
    "    s_test = mat_to_sets(m_test)\n",
    "    return m_train, m_test, m_input, m_hidden, s_train, s_test, s_input, s_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each user has liked at least 11 talent.\n"
     ]
    }
   ],
   "source": [
    "min_likes = like_df.sum(axis=1).min()\n",
    "print(\"Each user has liked at least {} talent.\".format(min_likes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Hold Out Split\n",
      "Type Train Hold Input Hidden\n",
      "Matrix 4000 1000 1000 1000\n",
      "Set 4000 1000 1000 1000\n",
      "\n",
      "Make Train/Test Split\n",
      "Type Test Hold Input Hidden\n",
      "Train 3000 1000 1000 1000\n",
      "Test 3000 1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Make Hold Out Split\")\n",
    "m_train, m_hold, m_hold_input, m_hold_hidden, s_train, s_hold, s_hold_input, s_hold_hidden = recs_train_test_split(\n",
    "    like_mat, test_size=0.2, min_entries=3, seed=0\n",
    ")\n",
    "print(\"Type\", \"Train\", \"Hold\", \"Input\", \"Hidden\")\n",
    "print(\"Matrix\",len(m_train), len(m_hold), len(m_hold_input), len(m_hold_hidden))\n",
    "print(\"Set\", len(s_train), len(s_hold), len(s_hold_input), len(s_hold_hidden))\n",
    "print()\n",
    "\n",
    "print(\"Make Train/Test Split\")\n",
    "m_train, m_test, m_input, m_hidden, s_train, s_test, s_input, s_hidden = recs_train_test_split(\n",
    "    m_train, test_size=0.25, min_entries=3, seed=0\n",
    ")\n",
    "print(\"Type\", \"Test\", \"Hold\", \"Input\", \"Hidden\")\n",
    "print(\"Train\",len(m_train), len(m_test), len(m_input), len(m_hidden))\n",
    "print(\"Test\", len(s_train), len(s_test), len(s_input), len(s_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mat Format: Wrote 3000 train records and 1000 test records to ../input/train_test_mat.pkl.\n",
      "Set Format: Wrote 3000 train records and 1000 test records to ../input/train_test_set.pkl.\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "mat_split = [csr_matrix(mat) for mat in (m_train, m_test, m_input, m_hidden)]\n",
    "set_split = (s_train, s_test, s_input, s_hidden)\n",
    "\n",
    "mat_file = \"../input/train_test_mat.pkl\"\n",
    "pickle.dump(mat_split, open(mat_file, \"wb\"))\n",
    "print(\"Mat Format: Wrote {} train records and {} test records to {}.\".format(len(m_train), len(m_test), mat_file))\n",
    "\n",
    "set_file = \"../input/train_test_set.pkl\"\n",
    "pickle.dump(set_split, open(set_file, \"wb\"))\n",
    "print(\"Set Format: Wrote {} train records and {} test records to {}.\".format(len(s_train), len(s_test), set_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mat Format: Wrote 1000 hold out input records to ../input/hold_mat.pkl.\n",
      "Set Format: Wrote 1000 hold out input records to ../input/hold_set.pkl.\n"
     ]
    }
   ],
   "source": [
    "mat_hold_file = \"../input/hold_mat.pkl\"\n",
    "pickle.dump(csr_matrix(m_hold_input), open(mat_hold_file, \"wb\"))\n",
    "print(\"Mat Format: Wrote {} hold out input records to {}.\".format(len(m_hold_input), mat_hold_file))\n",
    "\n",
    "set_hold_file = \"../input/hold_set.pkl\"\n",
    "pickle.dump(s_hold_input, open(set_hold_file, \"wb\"))\n",
    "print(\"Set Format: Wrote {} hold out input records to {}.\".format(len(s_hold_input), set_hold_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mat Format: Wrote 1000 hold out input records to ../input/hold_soln_mat.pkl.\n",
      "Set Format: Wrote 1000 hold out input records to ../input/hold_soln_set.pkl.\n"
     ]
    }
   ],
   "source": [
    "mat_hold_soln_split = [csr_matrix(mat) for mat in (m_hold, m_hold_input, m_hold_hidden)]\n",
    "set_hold_soln_split = (s_hold, s_hold_input, s_hold_hidden)\n",
    "\n",
    "mat_hold_soln_file = \"../input/hold_soln_mat.pkl\"\n",
    "pickle.dump(mat_hold_soln_split, open(mat_hold_soln_file, \"wb\"))\n",
    "print(\"Mat Format: Wrote {} hold out input records to {}.\".format(len(m_hold), mat_hold_soln_file))\n",
    "\n",
    "set_hold_soln_file = \"../input/hold_soln_set.pkl\"\n",
    "pickle.dump(set_hold_soln_split, open(set_hold_soln_file, \"wb\"))\n",
    "print(\"Set Format: Wrote {} hold out input records to {}.\".format(len(s_hold), set_hold_soln_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote test set solution file for 1000 users to ../output/kaggle_solution_test.csv.\n"
     ]
    }
   ],
   "source": [
    "soln_headers = [\"Id\", \"Expected\"]\n",
    "soln_file = \"../output/kaggle_solution_test.csv\"\n",
    "soln_n = write_kaggle_recs(s_hidden, soln_file, soln_headers)\n",
    "print(\"Wrote test set solution file for {} users to {}.\".format(soln_n, soln_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote hold out set solution file for 1000 users to ../output/kaggle_solution_hold.csv.\n"
     ]
    }
   ],
   "source": [
    "hold_headers = [\"Id\", \"Expected\"]\n",
    "hold_file = \"../output/kaggle_solution_hold.csv\"\n",
    "hold_n = write_kaggle_recs(s_hold_hidden, hold_file, hold_headers)\n",
    "print(\"Wrote hold out set solution file for {} users to {}.\".format(hold_n, hold_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote leaderboard solution file for 2000 users to ../output/kaggle_solution_leaderboard.csv.\n"
     ]
    }
   ],
   "source": [
    "# Write joint Kaggle file for public and private leaderboard\n",
    "full_file = \"../output/kaggle_solution_leaderboard.csv\"\n",
    "full_headers = [\"Id\", \"Expected\", \"Usage\"]\n",
    "full_lines = [\",\".join(full_headers)]\n",
    "all_hidden = s_hidden + s_hold_hidden\n",
    "all_usage = [\"Public\" for _ in s_hidden] + [\"Private\" for _ in s_hold_hidden]\n",
    "for i, (recs, usage) in enumerate(zip(all_hidden, all_usage)):\n",
    "    user_recs = \" \".join([str(v) for v in recs])\n",
    "    line = \"{},{},{}\".format(i, user_recs, usage)\n",
    "    full_lines.append(line)\n",
    "full_text = \"\\n\".join(full_lines)\n",
    "with open(full_file, \"w\") as file:\n",
    "    file.write(full_text)\n",
    "full_n = len(full_lines) - 1\n",
    "print(\"Wrote leaderboard solution file for {} users to {}.\".format(full_n, full_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtp_score(recs_true, recs_pred, k=10, adjusted=False):\n",
    "    \"\"\"\n",
    "    Computes the Mean Top Precision (MTP) score of recommendations.\n",
    "    For each user, top precision = # of correct recs / # of total recs\n",
    "    Where # of total recommendations is limited to the first t.\n",
    "    MTP is the mean of top precision across all users.\n",
    "    params:\n",
    "        recs_true: list of sets of hidden items for each user\n",
    "        recs_pred: list of lists of recommended items, with each list\n",
    "        sorted in order of decreasing relevance\n",
    "        k: number of recommendations to use in top set\n",
    "        adjusted: if True, adjust for the number of hidden items\n",
    "    \"\"\"\n",
    "    if len(recs_true) != len(recs_pred):\n",
    "        note = \"Length of true list {} does not match length of recommended list {}.\"\n",
    "        raise ValueError(note.format(len(recs_true), len(recs_pred)))\n",
    "    scores = []\n",
    "    for r_true, r_pred_orig in zip(recs_true, recs_pred):\n",
    "        r_pred = list(r_pred_orig)[0:k]\n",
    "        possible = k\n",
    "        # If a user has less than t hidden recs, then the\n",
    "        # maximum top precision cannot be reached\n",
    "        if adjusted:\n",
    "            possible = min(len(r_true), k)\n",
    "        intersect = set(r_true).intersection(set(r_pred))\n",
    "        prec = len(intersect) / possible\n",
    "        scores.append(prec)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTP  = 0.461\n",
      "MTP* = 0.462\n",
      "UHR  = 0.884\n",
      "MAP  = 0.364\n"
     ]
    }
   ],
   "source": [
    "from redcarpet import get_recs, mapk_score, uhr_score, collaborative_filter, jaccard_sim\n",
    "\n",
    "\n",
    "n_pred = len(s_input)\n",
    "n_top = 10\n",
    "s_scores = collaborative_filter(s_train, s_input[0:n_pred], sim_fn=jaccard_sim, k=n_top, j=30)\n",
    "s_pred = get_recs(s_scores)\n",
    "mtp = mtp_score(s_hidden[0:n_pred], s_pred, k=n_top)\n",
    "mtp_adj = mtp_score(s_hidden[0:n_pred], s_pred, k=n_top, adjusted=True)\n",
    "uhr = uhr_score(s_hidden[0:n_pred], s_pred, k=n_top)\n",
    "mapk = mapk_score(s_hidden[0:n_pred], s_pred, k=n_top)\n",
    "print(\"MTP  = {0:.3f}\".format(mtp))\n",
    "print(\"MTP* = {0:.3f}\".format(mtp_adj))\n",
    "print(\"UHR  = {0:.3f}\".format(uhr))\n",
    "print(\"MAP  = {0:.3f}\".format(mapk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote sample submission file of recommendations for 2000 users to ../output/kaggle_submission_sample.csv.\n"
     ]
    }
   ],
   "source": [
    "all_input = s_input + s_hold_input\n",
    "full_scores = collaborative_filter(s_train, all_input, sim_fn=jaccard_sim, k=n_top, j=30)\n",
    "full_pred = get_recs(full_scores)\n",
    "pred_headers = [\"Id\", \"Predicted\"]\n",
    "pred_file = \"../output/kaggle_submission_sample.csv\"\n",
    "pred_n = write_kaggle_recs(full_pred, pred_file, pred_headers)\n",
    "print(\"Wrote sample submission file of recommendations for {} users to {}.\".format(pred_n, pred_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
